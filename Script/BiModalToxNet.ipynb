{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import os\n",
    "import pydot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import HeNormal, GlorotUniform\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, GRU, Embedding, Attention, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, auc, average_precision_score, roc_curve, precision_recall_curve, recall_score, precision_score, matthews_corrcoef,accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the train images\n",
    "train_images_path = \"TrainCan Smiles images new\" # Replace with your train images path\n",
    "\n",
    "#Path to the train set\n",
    "train_set = \"Train Cleaned Data.xlsx\" # Replace with your train set path\n",
    "\n",
    "#Path to the test images\n",
    "test_images_path = \"TestCan Smiles images new\" # Replace with your test images path\n",
    "\n",
    "#Path to the test set\n",
    "test_set = \"Test Cleaned Data.xlsx\" # Replace with your test set path\n",
    "\n",
    "#Path to the External Validation set\n",
    "external_set = \"Cleaned External.xlsx\" # Replace with your external set path\n",
    "\n",
    "#Path to the Rat External Validation Images\n",
    "external_images_path = \"External Smiles images new\" # Replace with your external images path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(train_images_path):\n",
    "    # List all files in the folder\n",
    "    train_file_list = os.listdir(train_images_path)\n",
    "    train_image_files = [f for f in train_file_list if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    print(f\"Found {len(train_image_files)} image files in the folder.\")\n",
    "    # Sort the image filenames based on their string+numerical file name\n",
    "    sortedtrain_image_files = sorted(train_image_files, key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "    # Print the sorted image filenames\n",
    "    for index,sortedtrain_image_file in enumerate(sortedtrain_image_files):\n",
    "      print(f\"Index: {index}, Image: {sortedtrain_image_file}\")\n",
    "      \n",
    "      \n",
    "if os.path.exists(test_images_path):\n",
    "    # List all files in the folder\n",
    "    test_file_list = os.listdir(test_images_path)\n",
    "    test_image_files = [f for f in test_file_list if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    print(f\"Found {len(test_image_files)} image files in the folder.\")\n",
    "    # Sort the image filenames based on their string+numerical file name\n",
    "    sortedtest_image_files = sorted(test_image_files, key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "    # Print the sorted image filenames\n",
    "    for index,sortedtest_image_file in enumerate(sortedtest_image_files):\n",
    "      print(f\"Index: {index}, Image: {sortedtest_image_file}\")\n",
    "      \n",
    "\n",
    "\n",
    "if os.path.exists(external_images_path):\n",
    "    # List all files in the folder\n",
    "    external_file_list = os.listdir(external_images_path)\n",
    "    external_image_files = [f for f in external_file_list if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    print(f\"Found {len(external_image_files)} image files in the folder.\")\n",
    "    # Sort the image filenames based on their string+numerical file name\n",
    "    sortedexternal_image_files = sorted(external_image_files, key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "    # Print the sorted image filenames\n",
    "    for index,sortedexternal_image_file in enumerate(sortedexternal_image_files):\n",
    "      print(f\"Index: {index}, Image: {sortedexternal_image_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Train Label values \n",
    "Train_Toxicity = pd.read_excel(train_set)\n",
    "Train_Toxicity.shape\n",
    "Train_Eff_Toxicity = Train_Toxicity['Labels']\n",
    "print(Train_Eff_Toxicity.shape)\n",
    "\n",
    "\n",
    "# Load the Test Label values\n",
    "Test_Toxicity = pd.read_excel(test_set)\n",
    "Test_Toxicity.shape\n",
    "Test_Eff_Toxicity = Test_Toxicity['Labels']\n",
    "print(Test_Eff_Toxicity.shape)\n",
    "\n",
    "\n",
    "# Load the External Label values\n",
    "External_Toxicity = pd.read_excel(external_set)\n",
    "External_Toxicity.shape\n",
    "External_Eff_Toxicity = External_Toxicity['label']\n",
    "print(External_Eff_Toxicity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train image\n",
    "# Set the target size for resizing\n",
    "Train_target_Size = (128,128)\n",
    "\n",
    "# Create a list to store resized and preprocessed images\n",
    "Train_image_Arrays = []\n",
    "\n",
    "# Iterate over the imagers in the folder\n",
    "for Trainimage_file in sortedtrain_image_files:\n",
    "  Trainimage_path = os.path.join(train_images_path, Trainimage_file)\n",
    "  Trainimage = Image.open(Trainimage_path)\n",
    "\n",
    "  #  Resize the image to the target size\n",
    "  resizedtrain_Image = Trainimage.resize(Train_target_Size)\n",
    "\n",
    "  #  Convert the resized image into RGB\n",
    "  resizedtrain_Image_RGB = resizedtrain_Image.convert(\"RGB\")\n",
    "\n",
    "  # Convert the image to a NumPy array\n",
    "  Trainimage_Array = np.array(resizedtrain_Image_RGB)\n",
    "\n",
    "  # Normalize the Pixel values to the range [0,1]\n",
    "  Trainimage_Array = Trainimage_Array/255.0\n",
    "\n",
    "  # Ensure the image has the desired shape\n",
    "  if Trainimage_Array.shape != (Train_target_Size[0], Train_target_Size[1], 3):\n",
    "    Trainimage_Array = np.resize(Trainimage_Array, (Train_target_Size[0],Train_target_Size[1],3))\n",
    "\n",
    "  # Append the preprocessed image array to the list\n",
    "  Train_image_Arrays.append(Trainimage_Array)\n",
    "\n",
    "# Convert the List to a NumPy array\n",
    "Train_image_Arrays = np.array(Train_image_Arrays)\n",
    "\n",
    "\n",
    "\n",
    "# Test image\n",
    "# Set the target size for resizing\n",
    "Test_target_Size = (128,128)\n",
    "\n",
    "# Create a list to store resized and preprocessed images\n",
    "Test_image_Arrays = []\n",
    "\n",
    "# Iterate over the imagers in the folder\n",
    "for Testimage_file in sortedtest_image_files:\n",
    "  Testimage_path = os.path.join(test_images_path, Testimage_file)\n",
    "  Testimage = Image.open(Testimage_path)\n",
    "\n",
    "  #  Resize the image to the target size\n",
    "  resizedtest_Image = Testimage.resize(Test_target_Size)\n",
    "\n",
    "  #  Convert the resized image into RGB\n",
    "  resizedtest_Image_RGB = resizedtest_Image.convert(\"RGB\")\n",
    "\n",
    "  # Convert the image to a NumPy array\n",
    "  Testimage_Array = np.array(resizedtest_Image_RGB)\n",
    "\n",
    "  # Normalize the Pixel values to the range [0,1]\n",
    "  Testimage_Array = Testimage_Array/255.0\n",
    "\n",
    "  # Ensure the image has the desired shape\n",
    "  if Testimage_Array.shape != (Test_target_Size[0], Test_target_Size[1], 3):\n",
    "    Testimage_Array = np.resize(Testimage_Array, (Test_target_Size[0],Test_target_Size[1],3))\n",
    "\n",
    "  # Append the preprocessed image array to the list\n",
    "  Test_image_Arrays.append(Testimage_Array)\n",
    "\n",
    "# Convert the List to a NumPy array\n",
    "Test_image_Arrays = np.array(Test_image_Arrays)\n",
    "\n",
    "\n",
    "# External image\n",
    "# Set the target size for resizing\n",
    "External_target_Size = (128,128)\n",
    "\n",
    "# Create a list to store resized and preprocessed images\n",
    "External_image_Arrays = []\n",
    "\n",
    "# Iterate over the imagers in the folder\n",
    "for Externalimage_file in sortedexternal_image_files:\n",
    "  Externalimage_path = os.path.join(external_images_path, Externalimage_file)\n",
    "  Externalimage = Image.open(Externalimage_path)\n",
    "\n",
    "  #  Resize the image to the target size\n",
    "  resizedexternal_Image = Externalimage.resize(External_target_Size)\n",
    "\n",
    "  #  Convert the resized image into RGB\n",
    "  resizedexternal_Image_RGB = resizedexternal_Image.convert(\"RGB\")\n",
    "\n",
    "  # Convert the image to a NumPy array\n",
    "  Externalimage_Array = np.array(resizedexternal_Image_RGB)\n",
    "\n",
    "  # Normalize the Pixel values to the range [0,1]\n",
    "  Externalimage_Array = Externalimage_Array/255.0\n",
    "\n",
    "  # Ensure the image has the desired shape\n",
    "  if Externalimage_Array.shape != (External_target_Size[0], External_target_Size[1], 3):\n",
    "    Externalimage_Array = np.resize(Externalimage_Array, (External_target_Size[0],External_target_Size[1],3))\n",
    "\n",
    "  # Append the preprocessed image array to the list\n",
    "  External_image_Arrays.append(Externalimage_Array)\n",
    "\n",
    "# Convert the List to a NumPy array\n",
    "External_image_Arrays = np.array(External_image_Arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model for 2D molecular images\n",
    "def create_cnn_image_model(input_shape):\n",
    "    input_images = Input(shape=(Train_target_Size[0], Train_target_Size[1], 3))\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_images) \n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Conv2D(32, (3, 3), activation='relu', padding='same')(x1) \n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Conv2D(16, (3, 3), activation='relu', padding='same')(x1) \n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(16, activation='relu')(x1) \n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    print(x1.shape)\n",
    "    return input_images, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "Data = pd.read_excel(train_set)\n",
    "canon_SMILES = Data.SMILES\n",
    "\n",
    "# Function to calculate ECFPs from SMILES with error handling\n",
    "def calculate_ECFPs_from_SMILES(canon_SMILES, radius=2, n_bits=1024):\n",
    "    ecfp_list = []\n",
    "    for smiles in canon_SMILES:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "                ecfp_list.append(ecfp)\n",
    "            else:\n",
    "                # If the molecule is None, append a zero vector\n",
    "                ecfp_list.append([0] * n_bits)\n",
    "        except Exception as e:\n",
    "            # Handle any errors during fingerprint calculation by appending a zero vector\n",
    "            print(f\"Error calculating fingerprint for SMILES: {smiles}, Error: {e}\")\n",
    "            ecfp_list.append([0] * n_bits)\n",
    "    return ecfp_list\n",
    "\n",
    "# Calculate fingerprints again, handling errors\n",
    "ecfp_fingerprints = calculate_ECFPs_from_SMILES(canon_SMILES)\n",
    "\n",
    "# Convert the fingerprint bit vectors to a DataFrame\n",
    "ecfp_data = [list(ecfp) for ecfp in ecfp_fingerprints]  # Converting fingerprints to lists\n",
    "Morgan_Fps = pd.DataFrame(ecfp_data, columns=[f\"FP_{i+1}\" for i in range(1024)])\n",
    "\n",
    "# Ensure fingerprint_input is a NumPy array\n",
    "fingerprint_input = np.array(Morgan_Fps)\n",
    "print(f\"fingerprint_input shape: {fingerprint_input.shape}\")\n",
    "\n",
    "# Test\n",
    "TestData = pd.read_excel(test_set)\n",
    "testcanon_SMILES = TestData.SMILES\n",
    "\n",
    "# Function to calculate ECFPs from SMILES with error handling\n",
    "def calculate_ECFPs_from_SMILES(testcanon_SMILES, radius=2, n_bits=1024):\n",
    "    ecfp_list_test = []\n",
    "    for smiles in testcanon_SMILES:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "                ecfp_list_test.append(ecfp)\n",
    "            else:\n",
    "                # If the molecule is None, append a zero vector\n",
    "                ecfp_list_test.append([0] * n_bits)\n",
    "        except Exception as e:\n",
    "            # Handle any errors during fingerprint calculation by appending a zero vector\n",
    "            print(f\"Error calculating fingerprint for SMILES: {smiles}, Error: {e}\")\n",
    "            ecfp_list_test.append([0] * n_bits)\n",
    "    return ecfp_list_test\n",
    "\n",
    "# Calculate fingerprints again, handling errors\n",
    "testecfp_fingerprints = calculate_ECFPs_from_SMILES(testcanon_SMILES)\n",
    "\n",
    "# Convert the fingerprint bit vectors to a DataFrame\n",
    "testecfp_data = [list(ecfp) for ecfp in testecfp_fingerprints]  # Converting fingerprints to lists\n",
    "testMorgan_Fps = pd.DataFrame(testecfp_data, columns=[f\"FP_{i+1}\" for i in range(1024)])\n",
    "\n",
    "# Ensure fingerprint_input is a NumPy array\n",
    "testfingerprint_input = np.array(testMorgan_Fps)\n",
    "print(f\"Test fingerprint_input shape: {testfingerprint_input.shape}\")\n",
    "\n",
    "\n",
    "# External\n",
    "ExternalData = pd.read_excel(external_set)\n",
    "externalcanon_SMILES = ExternalData.Canonical_Smiles\n",
    "\n",
    "# Function to calculate ECFPs from SMILES with error handling\n",
    "def calculate_ECFPs_from_SMILES(externalcanon_SMILES, radius=2, n_bits=1024):\n",
    "    ecfp_list_external = []\n",
    "    for smiles in externalcanon_SMILES:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "                ecfp_list_external.append(ecfp)\n",
    "            else:\n",
    "                # If the molecule is None, append a zero vector\n",
    "                ecfp_list_external.append([0] * n_bits)\n",
    "        except Exception as e:\n",
    "            # Handle any errors during fingerprint calculation by appending a zero vector\n",
    "            print(f\"Error calculating fingerprint for SMILES: {smiles}, Error: {e}\")\n",
    "            ecfp_list_external.append([0] * n_bits)\n",
    "    return ecfp_list_external\n",
    "\n",
    "# Calculate fingerprints again, handling errors\n",
    "externalecfp_fingerprints = calculate_ECFPs_from_SMILES(externalcanon_SMILES)\n",
    "\n",
    "# Convert the fingerprint bit vectors to a DataFrame\n",
    "externalecfp_data = [list(ecfp) for ecfp in externalecfp_fingerprints]  # Converting fingerprints to lists\n",
    "externalMorgan_Fps = pd.DataFrame(externalecfp_data, columns=[f\"FP_{i+1}\" for i in range(1024)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_input = Morgan_Fps \n",
    "# Define the model for molecular fingerprint input\n",
    "def create_fingerprint_model(fingerprint_shape):\n",
    "    input_fingerprint = Input(shape=(fingerprint_shape,), name=\"fingerprint_input\")\n",
    "    x3 = Dense(64, activation='relu')(input_fingerprint)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "    x3 = Dense(32, activation='relu')(x3) \n",
    "    print(x3.shape)\n",
    "    return input_fingerprint, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# Define input shapes and parameters\n",
    "image_shape = (128, 128, 3) \n",
    "fingerprint_shape = 1024  \n",
    "\n",
    "# Test\n",
    "# Define input shapes and parameters\n",
    "testimage_shape = (128, 128, 3)  \n",
    "testfingerprint_shape = 1024  \n",
    "\n",
    "# External\n",
    "externalimage_shape = (128, 128, 3)  \n",
    "externalfingerprint_shape = 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# Create the individual models\n",
    "image_input, cnn_image_features = create_cnn_image_model(image_shape)\n",
    "fingerprint_input, fingerprint_features = create_fingerprint_model(fingerprint_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# Combine features from all models\n",
    "combined_features = Concatenate()([cnn_image_features, fingerprint_features])\n",
    "print(\"Combined features shape:\", combined_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected layers and binary classification output\n",
    "x = Dense(64, activation='relu')(combined_features) # Add regularizer, Initializer\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "#btch_norm2 = BatchNormalization()(x)\n",
    "output = Dense(1, activation='sigmoid')(x)# Binary classification\n",
    "#output = Flatten()(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate_metric(optimizer):\n",
    "    def learning_rate(y_true, y_pred):\n",
    "        return optimizer.learning_rate\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = Model(inputs=[image_input, fingerprint_input], outputs=output)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "learning_rate_metric = get_learning_rate_metric(optimizer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', learning_rate_metric])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If Train_imagfe_Arrays and Train_Effe_Toxicity are pandas Series or DataFrame, convert to numpy arrays\n",
    "Train_image_Arrays = np.array(Train_image_Arrays)\n",
    "Train_Eff_Toxicity = np.array(Train_Eff_Toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Get weights\n",
    "best_weights = []\n",
    "\n",
    "# Arrays to store performance metrics for each fold\n",
    "train_accuracy = []\n",
    "best_train_accs = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "specificity_scores = []\n",
    "sensitivity_scores = []\n",
    "f1_scores = []\n",
    "mcc_scores = []\n",
    "aurocs = []\n",
    "auprcs = []\n",
    "tps=[]\n",
    "tns=[]\n",
    "fps=[]\n",
    "fns=[]\n",
    "tpr_scores = [] \n",
    "fpr_scores = [] \n",
    "\n",
    "# Compute class weoghts\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(Train_Eff_Toxicity),y=Train_Eff_Toxicity)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Initialize a fold counter\n",
    "fold = 1\n",
    "\n",
    "# Loop over the 10 folds\n",
    "for train_index, val_index in skf.split(Train_Eff_Toxicity, Train_Eff_Toxicity):\n",
    "    # Split the data into train and validation sets\n",
    "    X_train_images, X_val_images = Train_image_Arrays[train_index], Train_image_Arrays[val_index]\n",
    "    X_train_smiles, X_val_smiles = padded_smiles[train_index], padded_smiles[val_index]\n",
    "    X_train_fingerprints, X_val_fingerprints = Morgan_Fps.iloc[train_index].values, Morgan_Fps.iloc[val_index].values\n",
    "    y_train, y_val = Train_Eff_Toxicity[train_index], Train_Eff_Toxicity[val_index]\n",
    "\n",
    "    callbacks_list = [\n",
    "    ModelCheckpoint(filepath=f'Multimodal_2_{fold}.keras', monitor='val_loss', save_best_only=True, verbose=1, mode='auto'),\n",
    "    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)]\n",
    "    start_time = time.time()\n",
    "    history =model.fit([X_train_images, X_train_smiles, X_train_fingerprints], y_train, epochs=30, batch_size=32, verbose=1, validation_data=(\n",
    "        [X_val_images, X_val_smiles, X_val_fingerprints], y_val), class_weight = class_weights_dict,  shuffle = True, callbacks=callbacks_list) # Use validation_data\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate training time for the current fold\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Fold Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    train_accuracy.append(history.history['accuracy'])\n",
    "\n",
    "    best_train_acc = max(history.history['accuracy'])\n",
    "    print(best_train_acc)\n",
    "    best_train_accs.append(best_train_acc)\n",
    "    \n",
    "    #Load the best weights for this fold\n",
    "    model.load_weights(f'Multimodal_2_{fold}.keras')\n",
    "    #Append the best weights to the list\n",
    "    best_weights.append(model.get_weights())\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict([X_val_images, X_val_smiles, X_val_fingerprints])\n",
    "    y_pred_labels = (y_pred > 0.5).astype(int) \n",
    "\n",
    "    # Calculate the metrices\n",
    "    cm = confusion_matrix(y_val,y_pred_labels)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Compute metrics for this fold\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred_labels)\n",
    "    recall = recall_score(y_val, y_pred_labels)\n",
    "    f1 = f1_score(y_val, y_pred_labels)\n",
    "    mcc = matthews_corrcoef(y_val, y_pred_labels)\n",
    "    auprc = average_precision_score(y_val, y_pred)\n",
    "    \n",
    "    # Sensitivity = Recall\n",
    "    sensitivity = recall\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Calculate TPR and FPR\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate (Sensitivity/Recall)\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    auc_scores.append(auc)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    mcc_scores.append(mcc)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificity_scores.append(specificity)\n",
    "    auprcs.append(auprc)\n",
    "    tps.append(tp)\n",
    "    tns.append(tn)\n",
    "    fps.append(fp)\n",
    "    fns.append(fn)\n",
    "    tpr_scores.append(tpr)\n",
    "    fpr_scores.append(fpr)\n",
    "\n",
    "    print(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\")\n",
    "    print(f\"Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}\")\n",
    "    print(f\"Specificity:{specificity:.4f}, Sensitivity:{sensitivity:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "    print(f\"AUC:{auc:.4f}, AUPRC:{auprc:.4f}\")\n",
    "    print(f\"TPR: {tpr:.4f}\")\n",
    "    print(f\"FPR: {fpr:.4f}\")\n",
    "\n",
    "    # Increment the fold counter\n",
    "    fold += 1\n",
    "\n",
    "\n",
    "print(f\"******************************************************\")\n",
    "# Compute average and standard deviation for each metric across all folds\n",
    "Train_acc = best_train_acc\n",
    "Val_acc = accuracy_scores\n",
    "Val_auroc = auc_scores\n",
    "np.save('Val AUROC_CNN+FCNN_rat',Val_auroc)\n",
    "Val_auprc = auprcs\n",
    "np.save('Val AUPRC_CNN+FCNN_rat',Val_auprc)\n",
    "Val_mcc = mcc_scores\n",
    "Val_f1 = f1_scores\n",
    "Val_sp = specificity_scores\n",
    "Val_se = sensitivity_scores\n",
    "Val_pr = precision_scores\n",
    "np.save('Val PR_CNN+FCNN_rat',Val_pr)\n",
    "Val_re = recall_scores\n",
    "np.save('Val RE_CNN+FCNN_rat',Val_re)\n",
    "Val_tp = tps\n",
    "Val_fp = fps\n",
    "Val_tn = tns\n",
    "Val_fn = fns\n",
    "Val_tpr = tpr_scores\n",
    "Val_fpr = fpr_scores\n",
    "np.save('Val TPR_CNN+FCNN_rat', Val_tpr)\n",
    "np.save('Val FPR_CNN+FCNN_rat', Val_fpr)\n",
    "\n",
    "Mean_Train_acc = np.mean(best_train_accs)\n",
    "Mean_Val_acc = np.mean(accuracy_scores)\n",
    "Mean_Val_auroc = np.mean(auc_scores)\n",
    "Mean_Val_auprc = np.mean(auprcs)\n",
    "Mean_Val_mcc = np.mean(mcc_scores)\n",
    "Mean_Val_f1 = np.mean(f1_scores)\n",
    "Mean_Val_sp = np.mean(specificity_scores)\n",
    "Mean_Val_se = np.mean(sensitivity_scores)\n",
    "Mean_Val_pr = np.mean(precision_scores)\n",
    "Mean_Val_re = np.mean(recall_scores)\n",
    "Mean_Val_tp = np.mean(tps)\n",
    "Mean_Val_tn = np.mean(tns)\n",
    "Mean_Val_fp = np.mean(fps)\n",
    "Mean_Val_fn = np.mean(fns)\n",
    "Mean_Val_tpr = np.mean(tpr_scores)\n",
    "Mean_Val_fpr = np.mean(fpr_scores)\n",
    "\n",
    "print(f\"Train Accuracy: {np.mean(best_train_accs):.4f} ± {np.std(best_train_accs):.4f}\")\n",
    "np.save('Mean_Train_acc_CNN+FCNN_rat',Mean_Train_acc)\n",
    "print(f\"Accuracy: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}\")\n",
    "np.save('Mean_Val_acc_CNN+FCNN_rat',Mean_Val_acc)\n",
    "print(f\"AUROC: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")\n",
    "np.save('Mean_AUROC_CNN+FCNN_rat',Mean_Val_auroc)\n",
    "print(f\"Precision: {np.mean(precision_scores):.4f} ± {np.std(precision_scores):.4f}\")\n",
    "np.save('Mean_Pr_CNN+FCNN_rat',Mean_Val_pr)\n",
    "print(f\"Recall: {np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\")\n",
    "np.save('Mean_Re_CNN+FCNN_rat',Mean_Val_re)\n",
    "print(f\"Specificity: {np.mean(specificity_scores):.4f} ± {np.std(specificity_scores):.4f}\")\n",
    "np.save('Mean_SP_CNN+FCNN_rat',Mean_Val_sp)\n",
    "print(f\"Sensitivity: {np.mean(sensitivity_scores):.4f} ± {np.std(sensitivity_scores):.4f}\")\n",
    "np.save('Mean_SE_CNN+FCNN_rat',Mean_Val_se)\n",
    "print(f\"MCC: {np.mean(mcc_scores):.4f} ± {np.std(mcc_scores):.4f}\")\n",
    "np.save('Mean_MCC_CNN+FCNN_rat',Mean_Val_mcc)\n",
    "print(f\"F1 Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
    "np.save('Mean_F1_CNN+FCNN_rat',Mean_Val_mcc)\n",
    "print(f\"AUPRC: {np.mean(auprcs):.4f} ± {np.std(auprcs):.4f}\")\n",
    "np.save('Mean_AUPRC_CNN+FCNN_rat',Mean_Val_auprc)\n",
    "print(f\"TP:{np.mean(tps)} ± {np.std(tps)}\")\n",
    "np.save('Mean_TP_CNN+FCNN_rat',Mean_Val_tp)\n",
    "print(f\"TN:{np.mean(tns)} ± {np.std(tns)}\")\n",
    "np.save('Mean_TN_CNN+FCNN_rat',Mean_Val_tn)\n",
    "print(f\"FP:{np.mean(fps)} ± {np.std(fps)}\")\n",
    "np.save('Mean_FP_CNN+FCNN_rat',Mean_Val_fp)\n",
    "print(f\"FN:{np.mean(fns)} ± {np.std(fns)}\")\n",
    "np.save('Mean_FN_CNN+FCNN_rat',Mean_Val_fn)\n",
    "print(f\"TPR:{np.mean(tpr_scores)} ± {np.std(tpr_scores)}\")\n",
    "np.save('Mean_TPR_CNN+FCNN_rat',Mean_Val_tpr)\n",
    "print(f\"FPR:{np.mean(fpr_scores)} ± {np.std(fpr_scores)}\")\n",
    "np.save('Mean_FPR_CNN+FCNN_rat',Mean_Val_fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new model as same as the above model and trained it using the best model from the above training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final multimodal model\n",
    "def create_Final_model(image_shape,fingerprint_shape):\n",
    "    # CNN branch for image input\n",
    "    input_images = Input(shape=(Train_target_Size[0], Train_target_Size[1], 3))\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_images)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Conv2D(32, (3, 3), activation='relu', padding='same')(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Conv2D(16, (3, 3), activation='relu', padding='same')(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(16, activation='relu')(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "\n",
    "    # Dense layers for fingerprint input\n",
    "    input_fingerprint = Input(shape=(fingerprint_shape,), name=\"fingerprint_input\")\n",
    "    x3 = Dense(64, activation='relu')(input_fingerprint)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "    x3= Dense(32, activation='relu')(x3)\n",
    "\n",
    "    # Combine the three branches\n",
    "    combined_features = Concatenate()([x1, x3])\n",
    "\n",
    "    # Fully connected layers after merging the inputs\n",
    "    x = Dense(64, activation='relu')(combined_features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(x)# Binary classification\n",
    "  \n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[input_images, input_fingerprint], outputs=output) \n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shapes and parameters\n",
    "image_shape = (128, 128, 3)  # Example image shape\n",
    "fingerprint_shape = 1024  # Example molecular fingerprint size\n",
    "\n",
    "# Initialize reference shapes for consistent model comparison\n",
    "ref_shape = None\n",
    "consistent_best_weights = []\n",
    "\n",
    "# Filter out inconsistent models based on their weight shapes\n",
    "for i, weights in enumerate(best_weights):\n",
    "    current_shape = [w.shape for w in weights]\n",
    "    if ref_shape is None:\n",
    "        # Set the reference shape from the first model\n",
    "        ref_shape = current_shape\n",
    "        consistent_best_weights.append(weights)\n",
    "    elif current_shape == ref_shape:\n",
    "        # Only add models with the same architecture\n",
    "        consistent_best_weights.append(weights)\n",
    "    else:\n",
    "        print(f\"Inconsistent model found at index {i+1} with shape: {current_shape}, skipping this model.\")\n",
    "\n",
    "# Check if there are enough consistent models to average weights\n",
    "if len(consistent_best_weights) > 1:\n",
    "    # Now proceed with averaging the consistent weights\n",
    "    averaged_weights = [\n",
    "        np.mean(np.array(weights_list), axis=0) for weights_list in zip(*consistent_best_weights)\n",
    "    ]\n",
    "else:\n",
    "    averaged_weights = consistent_best_weights[0]\n",
    "   \n",
    "# Create a new model and set the averaged weights\n",
    "model = create_Final_model(image_shape, fingerprint_shape)  # Pass required arguments\n",
    "model.set_weights(averaged_weights)\n",
    "\n",
    "# Compile the model with the optimizer and metrics\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy', learning_rate_metric])\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(Train_Eff_Toxicity), y=Train_Eff_Toxicity)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Callbacks\n",
    "callbacks_list_1 = [\n",
    "    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([Train_image_Arrays, Morgan_Fps], Train_Eff_Toxicity, \n",
    "                    batch_size=32, epochs=30, verbose=1, \n",
    "                    class_weight=class_weights_dict, \n",
    "                    shuffle=True, \n",
    "                    validation_data=([Test_image_Arrays, testMorgan_Fps.values], Test_Eff_Toxicity), \n",
    "                    callbacks=callbacks_list_1)\n",
    "\n",
    "print(f\" Results for Test set:\") \n",
    "\n",
    "# Evaluate the model\n",
    "loss,accuracy,learning_rate = model.evaluate([Test_image_Arrays, testMorgan_Fps.values], Test_Eff_Toxicity)\n",
    "# evaluate only with external validation set\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict([Test_image_Arrays, testMorgan_Fps.values])\n",
    "y_test_pred_labels = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics using the actual test labels and the predicted labels\n",
    "cm_test = confusion_matrix(Test_Eff_Toxicity, y_test_pred_labels)\n",
    "tnt, fpt, fnt, tpt = cm_test.ravel()\n",
    "\n",
    "# Accuracy, Precision, Recall, F1, MCC, and other metrics\n",
    "accuracy_test = accuracy_score(Test_Eff_Toxicity, y_test_pred_labels)\n",
    "accuracy_testf = (tpt + tnt) / (tpt + fpt + fnt + tnt)\n",
    "auc_test = roc_auc_score(Test_Eff_Toxicity, y_test_pred)\n",
    "precision_test = precision_score(Test_Eff_Toxicity, y_test_pred_labels)\n",
    "recall_test = recall_score(Test_Eff_Toxicity, y_test_pred_labels)\n",
    "f1_test = f1_score(Test_Eff_Toxicity, y_test_pred_labels)\n",
    "mcc_test = matthews_corrcoef(Test_Eff_Toxicity, y_test_pred_labels)\n",
    "auprc_test = average_precision_score(Test_Eff_Toxicity, y_test_pred)\n",
    "# Sensitivity = Recall\n",
    "sensitivity_test = recall_test\n",
    "# Specificity calculation\n",
    "specificity_test = tnt / (tnt + fpt)\n",
    "\n",
    "# Calculate TPR and FPR for test set\n",
    "tpr_test = tpt / (tpt + fnt)\n",
    "fpr_test = fpt / (fpt + tnt)\n",
    "\n",
    "# Print out the metrics\n",
    "print(f\"Final Evaluation on Test Set:\")\n",
    "print(f\"True Positive (TP): {tpt}\")\n",
    "np.save('Test TP_CNN+FCNN_rat',tpt)\n",
    "print(f\"True Negative (TN): {tnt}\")\n",
    "np.save('Test TN_CNN+FCNN_rat',tnt)\n",
    "print(f\"False Positive (FP): {fpt}\")\n",
    "np.save('Test FP_CNN+FCNN_rat',fpt)\n",
    "print(f\"False Negative (FN): {fnt}\")\n",
    "np.save('Test FN_CNN+FCNN_rat',fnt)\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Test Accuracyf: {accuracy_testf:.4f}\")\n",
    "np.save('Test ACC_CNN+FCNN_rat',accuracy_test)\n",
    "print(f\"Test Precision: {precision_test:.4f}\")\n",
    "np.save('Test PR_CNN+FCNN_rat',precision_test)\n",
    "print(f\"Test Recall: {recall_test:.4f}\")\n",
    "np.save('Test RE_CNN+FCNN_rat',recall_test)\n",
    "print(f\"Test F1 Score: {f1_test:.4f}\")\n",
    "np.save('Test F1_CNN+FCNN_rat',f1_test)\n",
    "print(f\"Test MCC: {mcc_test:.4f}\")\n",
    "np.save('Test MCC_CNN+FCNN_rat',mcc_test)\n",
    "print(f\"Test Specificity: {specificity_test:.4f}\")\n",
    "np.save('Test SP_CNN+FCNN_rat',specificity_test)\n",
    "print(f\"Test Sensitivity: {sensitivity_test:.4f}\")\n",
    "np.save('Test SE_CNN+FCNN_rat',sensitivity_test)\n",
    "print(f\"Test AUROC: {auc_test:.4f}\")\n",
    "np.save('Test AUROC_CNN+FCNN_rat',auc_test)\n",
    "print(f\"Test AUPRC: {auprc_test:.4f}\")\n",
    "np.save('Test AUPRC_CNN+FCNN_rat',auprc_test)\n",
    "print(f\"Test TPR: {tpr_test:.4f}\")\n",
    "np.save('Test TPR_CNN+FCNN_rat',tpr_test)\n",
    "print(f\"Test FPR: {fpr_test:.4f}\")\n",
    "np.save('Test FPR_CNN+FCNN_rat',fpr_test)\n",
    "\n",
    "print(f\" Results for External set:\") \n",
    "# Evaluate the model\n",
    "loss,accuracy,learning_rate = model.evaluate([External_image_Arrays, externalMorgan_Fps.values], External_Eff_Toxicity)\n",
    "# evaluate only with external validation set\n",
    "print(\"External External Loss:\", loss)\n",
    "print(\"External External Accuracy:\", accuracy)\n",
    "\n",
    "# Predict on the test set\n",
    "y_external_pred = model.predict([External_image_Arrays, externalMorgan_Fps.values])\n",
    "y_external_pred_labels = (y_external_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics using the actual test labels and the predicted labels\n",
    "cm_external = confusion_matrix(External_Eff_Toxicity, y_external_pred_labels)\n",
    "tn_e, fp_e, fn_e, tp_e = cm_external.ravel()\n",
    "\n",
    "# Accuracy, Precision, Recall, F1, MCC, and other metrics\n",
    "accuracy_external = accuracy_score(External_Eff_Toxicity, y_external_pred_labels)\n",
    "auc_external = roc_auc_score(External_Eff_Toxicity, y_external_pred)\n",
    "precision_external = precision_score(External_Eff_Toxicity, y_external_pred_labels)\n",
    "recall_external = recall_score(External_Eff_Toxicity, y_external_pred_labels)\n",
    "f1_external = f1_score(External_Eff_Toxicity, y_external_pred_labels)\n",
    "mcc_external = matthews_corrcoef(External_Eff_Toxicity, y_external_pred_labels)\n",
    "auprc_external = average_precision_score(External_Eff_Toxicity, y_external_pred)\n",
    "# Sensitivity = Recall\n",
    "sensitivity_external = recall_external\n",
    "# Specificity calculation\n",
    "specificity_external = tn_e / (tn_e + fp_e)\n",
    "\n",
    "# Calculate TPR and FPR for external set\n",
    "tpr_external = tp_e / (tp_e + fn_e)\n",
    "fpr_external = fp_e / (fp_e + tn_e)\n",
    "\n",
    "# Print out the metrics\n",
    "print(f\"Final Evaluation on External Set:\")\n",
    "print(f\"True Positive (TP): {tp_e}\")\n",
    "np.save('External TP_CNN+FCNN_external',tp_e)\n",
    "print(f\"True Negative (TN): {tn_e}\")\n",
    "np.save('External TN_CNN+FCNN_external',tn_e)\n",
    "print(f\"False Positive (FP): {fp_e}\")\n",
    "np.save('External FP_CNN+FCNN_external',fp_e)\n",
    "print(f\"False Negative (FN): {fn_e}\")\n",
    "np.save('External FN_CNN+FCNN_external',fn_e)\n",
    "print(f\"External Accuracy: {accuracy_external:.4f}\")\n",
    "np.save('External ACC_CNN+FCNN_external',accuracy_external)\n",
    "print(f\"External Precision: {precision_external:.4f}\")\n",
    "np.save('External PR_CNN+FCNN_external',precision_external)\n",
    "print(f\"External Recall: {recall_external:.4f}\")\n",
    "np.save('External RE_CNN+FCNN_external',recall_external)\n",
    "print(f\"External F1 Score: {f1_external:.4f}\")\n",
    "np.save('External F1_CNN+FCNN_external',f1_external)\n",
    "print(f\"External MCC: {mcc_external:.4f}\")\n",
    "np.save('External MCC_CNN+FCNN_external',mcc_external)\n",
    "print(f\"External Specificity: {specificity_external:.4f}\")\n",
    "np.save('External SP_CNN+FCNN_external',specificity_external)\n",
    "print(f\"External Sensitivity: {sensitivity_external:.4f}\")\n",
    "np.save('External SE_CNN+FCNN_external',sensitivity_external)\n",
    "print(f\"External AUROC: {auc_external:.4f}\")\n",
    "np.save('External AUROC_CNN+FCNN_external',auc_external)\n",
    "print(f\"External AUPRC: {auprc_external:.4f}\")\n",
    "np.save('External AUPRC_CNN+FCNN_external',auprc_external)\n",
    "print(f\"External TPR: {tpr_external:.4f}\")\n",
    "np.save('External TPR_CNN+FCNN_external',tpr_external)\n",
    "print(f\"External FPR: {fpr_external:.4f}\")\n",
    "np.save('External FPR_CNN+FCNN_external',fpr_external)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
